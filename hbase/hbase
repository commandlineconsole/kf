------------------------
jps
ssh localhost

start-all.sh
start-hbase.sh

jps
Hbase-shell
create 'table1' 'colfamily'
describe 'table1'
------------------------
scan 'test1'
disable 'test1'
drop 'test1'

------------------------
create 'emp2', 'personnal_data','profession_data'

scan 'emp2'

put 'emp2', '1, 'personnal_data:name', 'Ja'
put 'emp2', '2, 'personnal_data:name', 'ram'
put 'emp2', '1, 'profession_data:Desgination', 'Manager'
put 'emp2', '2, 'profession_data:name', 'sr Manager'

scan 'emp2'

delete 'emp', '1', 'personnal_data: name', timestamp
delete 'emp', '1', 'personnal_data: name', 150000221211

get 'emp', '2'
get 'emp', '1'
get 'emp', '1', {COLUMN => 'personnal_data: name'}

----------------------------

create ‘tab3′,’cf’

bin/hadoop fs -copyFromLocal simple1.txt  /user/hadoop/simple1.txt

"bin/hbase
org.apache.hadoop.hbase.mapreduce.ImportTsv
-Dimporttsv.separator=”,”
-Dimporttsv.columns=HBASE_ROW_KEY,cf tab4
/user/hadoop/simple1.txt"

-----------

create ‘hbase-tb1-003′,’cf’

B) USING IMPORTTSV TO GENERATE HFILE FOR TXT IN HDFS
command：
bin/hbase org.apache.hadoop.hbase.mapreduce.ImportTsv
-Dimporttsv.separator=”,”
-Dimporttsv.bulk.output=hfile_tmp5    //
-Dimporttsv.columns=HBASE_ROW_KEY,cf hbase-tbl-003
/user/hadoop/simple1.txt

-------------------

http://blogs.perficient.com/delivery/blog/2015/09/09/some-ways-load-data-from-hdfs-to-hbase/

hadoop jar lib/hbase-server-0.98.13-hadoop2.jar
completebulkload hfile_tmp5 hbase-tbl-003

B) USING IMPORTTSV TO GENERATE HFILE FOR TXT IN HDFS
command：

bin/hbase
org.apache.hadoop.hbase.mapreduce.ImportTsv
-Dimporttsv.separator=”,”
-Dimporttsv.bulk.output=hfile_tmp5
-Dimporttsv.columns=HBASE_ROW_KEY,cf hbase-tbl-003
/user/hadoop/simple1.txt

3.Using completebulkload to load Hfile to HBase
command:
hadoop jar lib/hbase-server-0.98.13-hadoop2.jar
completebulkload hfile_tmp5 hbase-tbl-003






